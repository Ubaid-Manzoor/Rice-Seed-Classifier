{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T11:24:43.635297Z",
     "start_time": "2019-05-17T11:24:43.531800Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%run DataUtilsModule.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T11:24:43.868026Z",
     "start_time": "2019-05-17T11:24:43.797969Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    \n",
    "    def load_data(self):\n",
    "        raise NotImplementedError(\"Load_data() Need To be Implemented\")\n",
    "    \n",
    "    def create_placeholders(self):\n",
    "        raise NotImplementedError(\"create_placeholders() Needs to be Implemented\")\n",
    "        \n",
    "    def initialize_parameters(self):\n",
    "        raise NotImplementedError(\"initialize_parameters() Needs to be Implemented\")\n",
    "        \n",
    "    def create_feed_dict(self , input_batch , label_batch):\n",
    "        raise NotImplementedError(\"create_feed_dict() Needs to be Implemented\")\n",
    "        \n",
    "    def add_forward_model(self , input_data):\n",
    "        raise NotImplementedError(\"add_model() Needs to be Implemented\")\n",
    "        \n",
    "    def add_cost_op(self , predict):\n",
    "        raise NotImplementedError(\"add_loss_op() Needs to be Implemented\")\n",
    "    \n",
    "    def run_epoch(self , sess , input_data , input_labels):\n",
    "        raise NotImplementedError(\"run_epoch Needs to be Implemented\")\n",
    "    \n",
    "    def fit(self):\n",
    "        raise NotImplementedError(\"fit() Needs to be Implemented\")\n",
    "        \n",
    "    def predict(self , sess , input_data , input_labels=None):\n",
    "        raise NotImplementedError(\"predict() Needs to be Implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-17T11:29:04.036401Z",
     "start_time": "2019-05-17T11:29:03.958834Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class cnn(Model):\n",
    "    def __init__(self):\n",
    "        tf.set_random_seed(1)\n",
    "        self.img_height = None\n",
    "        self.img_width = None\n",
    "        self.img_channel = None\n",
    "        self.totalClasses = 5\n",
    "        self.learning_parameter_shape = {}\n",
    "        self.learning_parameters = {}\n",
    "        self.non_learning_parameters = {}\n",
    "        self.stride = None\n",
    "        self.window_size = None\n",
    "        self.gray_scale = False\n",
    "        self.dropout = []\n",
    "        self.fully_connented_dims = []\n",
    "        self.learning_rate = 0.001\n",
    "        self.num_epochs=50\n",
    "        self.dataPath = '../data/working/'\n",
    "        self.minibatch_size = 64\n",
    "        self.m = None\n",
    "        #Funtion\n",
    "        self.load_data()\n",
    "        self.apply_one_hot()\n",
    "        self.__set_shape_var_of_Eachlayers()\n",
    "    \n",
    "    def apply_one_hot(self):\n",
    "        self.Y_train = tf.one_hot(self.Y_train , self.totalClasses)\n",
    "        self.Y_test = tf.one_hot(self.Y_test , self.totalClasses)\n",
    "        self.Y_dev = tf.one_hot(self.Y_dev , self.totalClasses)\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            self.Y_train , self.Y_test,self.Y_dev = sess.run([self.Y_train , self.Y_test , self.Y_dev]) \n",
    "        print(\"After OneHot\")\n",
    "        print(self.X_train.shape)\n",
    "        print(self.Y_train.shape)\n",
    "\n",
    "        print(self.X_test.shape)\n",
    "        print(self.Y_test.shape)\n",
    "\n",
    "        print(self.X_dev.shape)\n",
    "        print(self.Y_dev.shape)\n",
    "            \n",
    "    def load_data(self):\n",
    "        #if Data is Already is stored\n",
    "        if(utils.ifDataExits('X_Train' , self.dataPath)):\n",
    "            self.X_train , self.X_test , self.X_dev , self.Y_train , self.Y_test , self.Y_dev \\\n",
    "                                                                        = utils.load_saved_data()\n",
    "            print(self.X_train.shape)\n",
    "            print(self.Y_train.shape)\n",
    "\n",
    "            print(self.X_test.shape)\n",
    "            print(self.Y_test.shape)\n",
    "\n",
    "            print(self.X_dev.shape)\n",
    "            print(self.Y_dev.shape)\n",
    "        else:\n",
    "            self.X_train,self.X_test,self.Y_train,self.Y_test,self.X_dev,self.Y_dev  = utils.load_data(5 ,img_size=100 , batch_size=400) \n",
    "    def __set_shape_var_of_Eachlayers(self):\n",
    "        #For Learning Parameters\n",
    "        filter_shape = [\n",
    "                            [4,4,1,8] ,  #Layer 1\n",
    "                            [4,4,8,16] , #Layer 2\n",
    "                            [4,4,16,32] ,#Layer 3 \n",
    "                            [4,4,32,32] ,#Layer 4\n",
    "                            [4,4,32,64]  #Layer 5\n",
    "                        ]\n",
    "        if not self.gray_scale:\n",
    "            filter_shape[0][2] = 3 \n",
    "        \n",
    "        for index,shape in enumerate(filter_shape):\n",
    "            layer = index+1\n",
    "            self.learning_parameter_shape[\"W\" + str(layer)] = shape\n",
    "        print(\"Shape :\" , self.learning_parameter_shape)\n",
    "        #For Non-Learning Parameters\n",
    "        \n",
    "        #[for first maxpool layer,for second,for third , ...]\n",
    "        self.window_size = [2,2,2,2,2]\n",
    "        #[stride of conv layer , stride for max pool layer]\n",
    "        self.stride = [[1,2] , [1,2] , [1,2] , [1,2] , [1,2]]\n",
    "        self.dropout = [0 , 0 ,0.3 , 0.4 , 0.4]\n",
    "        \n",
    "        #Shape For FullyConnected Layer\n",
    "        self.fully_connented_dims = [128 , 64 , 5] #for last Layer except sofmax Layer\n",
    "        \n",
    "    def __create_placeholders(self):\n",
    "        X = tf.placeholder(dtype=tf.float32 , \n",
    "                           shape=[None , self.img_height , self.img_width , self.img_channel] ,\n",
    "                           name = 'input_values'\n",
    "                          )\n",
    "        Y = tf.placeholder(dtype=tf.float32 ,\n",
    "                           shape=[None , self.totalClasses] ,\n",
    "                           name=\"input_labels\"\n",
    "                          )\n",
    "        return X,Y\n",
    "    \n",
    "    def __initialize_learning_parameters(self):\n",
    "        layers = len(self.learning_parameter_shape)\n",
    "        for l in range(1, layers+1):\n",
    "            self.learning_parameters[\"W\"+str(l)]= \\\n",
    "                                    tf.get_variable(\"W\"+str(l) ,\n",
    "                                                    self.learning_parameter_shape[\"W\"+str(l)] ,\n",
    "                                                    initializer=tf.contrib.layers.xavier_initializer(seed=1)\n",
    "                                                   )\n",
    "        print(\"Parameters\" , self.learning_parameters)\n",
    "    def __initialize_non_learning_parameters(self):\n",
    "        layers = len(self.stride)\n",
    "        \n",
    "        for l in range(1,layers + 1):\n",
    "            self.non_learning_parameters[\"Conv_s\"+str(l)] = self.stride[l-1][0]\n",
    "            self.non_learning_parameters[\"Maxpool_s\"+str(l)] = self.stride[l-1][1]\n",
    "            self.non_learning_parameters[\"Window_size\"+str(l)] = self.window_size[l-1]\n",
    "            self.non_learning_parameters[\"dropout\"+str(l)] = self.dropout[l-1]\n",
    "            \n",
    "        \n",
    "    def __initialize_parameters(self):\n",
    "        self.__set_shape_var_of_Eachlayers()\n",
    "        \n",
    "        self.__initialize_learning_parameters()\n",
    "        self.__initialize_non_learning_parameters()\n",
    "\n",
    "        \n",
    "    def __create_feed_dict(self , input_batch , label_batch):\n",
    "        feed_dict = {}\n",
    "        feed_dict[self.X] = input_batch\n",
    "        feed_dict[self.Y] = label_batch\n",
    "        \n",
    "        return feed_dict\n",
    "    \n",
    "    def layersBeforeFlatten(self, X):\n",
    "        LP = self.learning_parameters\n",
    "        NLP = self.non_learning_parameters\n",
    "        layers = len(LP)\n",
    "        \n",
    "        for l in range(1,layers+1):\n",
    "            #Extract All parameters Needed\n",
    "            conv_s = NLP[\"Conv_s\"+str(l)]\n",
    "            f = NLP[\"Window_size\"+str(l)]\n",
    "            pool_s = NLP[\"Maxpool_s\"+str(l)]\n",
    "            curr_filter = LP[\"W\"+str(l)]\n",
    "            print(\"curr_filter\" , curr_filter)\n",
    "                \n",
    "            #CONV Layer\n",
    "            s = conv_s\n",
    "            Z = tf.nn.conv2d(X , curr_filter , strides=[1,s,s,1] , padding='SAME')\n",
    "            \n",
    "            #Activation\n",
    "            A = tf.nn.relu(Z)\n",
    "            \n",
    "            #Maxpool\n",
    "            s = pool_s\n",
    "            features = tf.nn.max_pool(A , ksize=[1,f,f,1] , strides=[1,s,s,1] , padding='SAME')\n",
    "            X = features\n",
    "        return features\n",
    "\n",
    "    def LayersAfterFlatten(self , X):\n",
    "        layers = len(self.fully_connented_dims)\n",
    "        \n",
    "        for l in range(1,layers+1):\n",
    "            Z = tf.contrib.layers.fully_connected(X  , self.fully_connented_dims[l-1] , activation_fn=None)\n",
    "        return Z\n",
    "    \n",
    "    def __add_forward_model(self , input_data):\n",
    "        X = self.layersBeforeFlatten(input_data)\n",
    "        \n",
    "        X_flatten = tf.contrib.layers.flatten(X)\n",
    "        \n",
    "        Z = self.LayersAfterFlatten(X_flatten)\n",
    "        \n",
    "        return Z\n",
    "    \n",
    "    def add_cost_op(self , predict , Y):\n",
    "        print(\"Predict\" , np.array(predict).shape)\n",
    "        print(\"Cross_entropy {}\".format(tf.nn.softmax_cross_entropy_with_logits(logits=predict , labels=Y)))\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predict , labels=Y))\n",
    "        print(\"Cost {}\".format(cost))\n",
    "        return cost\n",
    "    \n",
    "    def get_random_mini_batch(self ,mini_batch_size = 64):\n",
    "        mini_batches = []\n",
    "        \n",
    "        #About Random actually data is already Shuffled\n",
    "\n",
    "        num_compelete_minibatches = math.floor(self.m / mini_batch_size)\n",
    "        for k in range(num_compelete_minibatches):\n",
    "            mini_batch_X = self.X_train[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n",
    "            mini_batch_Y = self.Y_train[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "            mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "            mini_batches.append(mini_batch)\n",
    "        \n",
    "        if self.m%num_compelete_minibatches != 0:\n",
    "            mini_batch_X = self.X_train[num_complete_minibatches * mini_batch_size : m,:,:,:]\n",
    "            mini_batch_Y = self.Y_train[num_complete_minibatches * mini_batch_size : m,:]\n",
    "            mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "            mini_batches.append(mini_batch)\n",
    "\n",
    "        return mini_batches\n",
    "    \n",
    "    def run_epoch(self , sess , input_data , input_label):\n",
    "        epoch_cost = 0\n",
    "        minibatches = self.get_random_mini_batch()\n",
    "\n",
    "        for minibatch in minibatches:\n",
    "            mini_X , mini_Y = minibatch\n",
    "\n",
    "            _ , temp_cost , temp_acc= sess.run([self.optimizer , self.cost , self.accuracy] , \n",
    "                                     feed_dict = {self.X:mini_X , self.Y:mini_Y})\n",
    "            print(temp_acc)\n",
    "            epoch_cost += temp_cost\n",
    "        \n",
    "        return epoch_cost \n",
    "    \n",
    "    def add_accuracy(self):\n",
    "        Xtrain_labels = self.__add_forward_model(tf.cast(self.X_train , \"float32\"))\n",
    "        Xtest_labels = self.__add_forward_model(tf.cast(self.X_test , \"float32\"))\n",
    "        Xdev_labels = self.__add_forward_model(tf.cast(self.X_dev , \"float32\"))\n",
    "        \n",
    "        correct_prediction_forTrain = tf.equal(tf.argmax(Xtrain_labels,1) , tf.argmax(self.Y_train,1))\n",
    "        correct_prediction_forTest = tf.equal(tf.argmax(Xtest_labels,1) , tf.argmax(self.Y_test,1))\n",
    "        correct_prediction_forDev = tf.equal(tf.argmax(Xdev_labels,1) , tf.argmax(self.Y_dev,1))\n",
    "        \n",
    "        train_acc = tf.reduce_mean(tf.cast(correct_prediction_forTrain , \"float\"))\n",
    "        dev_acc = tf.reduce_mean(tf.cast(correct_prediction_forTest , \"float\"))\n",
    "        test_acc = tf.reduce_mean(tf.cast(correct_prediction_forDev , \"float\"))\n",
    "        \n",
    "        return [train_acc , dev_acc , test_acc]\n",
    "\n",
    "    def fit(self):\n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.m , self.img_height , self.img_width , self.img_channel = self.X_train.shape\n",
    "        self.totalClasses = self.Y_train.shape[1]\n",
    "        \n",
    "        self.X,self.Y = self.__create_placeholders()\n",
    "        \n",
    "        self.__initialize_parameters()\n",
    "        \n",
    "        Z = self.__add_forward_model(self.X)\n",
    "        \n",
    "        self.cost = self.add_cost_op(Z ,self.Y)\n",
    "        \n",
    "        self.accuracy = self.add_accuracy()\n",
    "        \n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "        \n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            costs = []\n",
    "            \n",
    "            for epoch in range(self.num_epochs):\n",
    "                epoch_cost  = self.run_epoch(sess , self.X_train , self.Y_train)\n",
    "                print(\"Cost after Epoch %i: %f\" % (epoch + 1 , epoch_cost) \n",
    "#                       \"=> Training Acc : %f\" %(accuracySet[0]),\n",
    "#                       \"=> Dev Acc : %f\" %(accuracySet[1]),\n",
    "#                       \"=> Test Acc : %f\" %(accuracySet[2])\n",
    "                     )\n",
    "                costs.append(epoch_cost)\n",
    "        \n",
    "        plt.plot(range(1,self.num_epochs+1) , costs)\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iteration')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
